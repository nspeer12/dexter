{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 - Importing Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import time\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from data_loader import VideoFolder\n",
    "from torchvision.transforms import Compose\n",
    "from RT3D_16F import FullModel\n",
    "import transforms as t\n",
    "import utils\n",
    "from tensorboardX import SummaryWriter\n",
    "from IPython.core.display import HTML\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "writer = SummaryWriter()\n",
    "\n",
    "with open('./configs.json') as data_file:\n",
    "    config = json.load(data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "curr_folder = 'full_net_10'\n",
    "if not os.path.exists(curr_folder):\n",
    "    os.makedirs(curr_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 14\n",
    "steps_before_print = 1000\n",
    "num_workers = 0\n",
    "step_size = 2\n",
    "num_frames = 32 // step_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 - Seting up Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "std, mean = [0.2674,  0.2676,  0.2648], [ 0.4377,  0.4047,  0.3925]\n",
    "transform = Compose([\n",
    "    t.GroupResize((100, 160)),\n",
    "    t.GroupRandomCrop((140, 100)),\n",
    "    t.GroupRandomRotation(18),\n",
    "    t.GroupToTensor(),\n",
    "    t.GroupNormalize(std=std, mean=mean),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "transform_validation = Compose([\n",
    "    t.GroupResize((100, 160)),\n",
    "    t.GroupRandomCrop((140, 100)),\n",
    "    t.GroupToTensor(),\n",
    "    t.GroupNormalize(std=std, mean=mean),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = VideoFolder(\n",
    "    root=config['train_data_folder'],\n",
    "    csv_file_input=config['full_train_data_csv'],\n",
    "    csv_file_labels=config['full_labels_csv'],\n",
    "    clip_size=num_frames,\n",
    "    nclips=1,\n",
    "    step_size=step_size,\n",
    "    is_val=False,\n",
    "    transform=transform,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_data,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=False, #changed\n",
    "    drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "validation_data = VideoFolder(\n",
    "    root=config['train_data_folder'],\n",
    "    csv_file_input=config['full_validation_data_csv'],\n",
    "    csv_file_labels=config['full_labels_csv'],\n",
    "    clip_size=num_frames,\n",
    "    nclips=1,\n",
    "    step_size=step_size,\n",
    "    is_val=False,\n",
    "    transform=transform_validation,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "validation_loader = torch.utils.data.DataLoader(\n",
    "    validation_data,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=False, #changed\n",
    "    drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_model(model, use_ts=False):\n",
    "    if use_ts:\n",
    "        time_stamp = time.strftime(\"%d_%b_%Y_%Hh%Mm\", time.gmtime())\n",
    "        torch.save(model.state_dict(), curr_folder + '/{}.ckp'.format(time_stamp))\n",
    "    else:\n",
    "        torch.save(model.state_dict(), curr_folder + '/{}.ckp'.format('best_model'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 - Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = FullModel(batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_recent_file = ''\n",
    "for file in os.listdir(curr_folder):\n",
    "    if file.endswith(\".ckp\"):\n",
    "        file = os.path.join(\".\", file)\n",
    "        if(file > most_recent_file):\n",
    "            most_recent_file = file\n",
    "if(most_recent_file != ''):\n",
    "    print('Model LOADED: ', curr_folder + '/' + most_recent_file)\n",
    "    loaded_dict = torch.load(curr_folder + '/' + most_recent_file)\n",
    "    model.load_state_dict(loaded_dict)\n",
    "else:\n",
    "    print('No model loaded.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print('Cuda is available!')\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(epochs):\n",
    "    \n",
    "    print(\"Trainning is about to start...\")\n",
    "    best_valdiation_loss = model.best_valdiation_loss\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        step = 0\n",
    "        epoch_loss = 0\n",
    "        epoch_acc = 0\n",
    "        times_calculated = 0\n",
    "        total_size = len(train_loader)\n",
    "        for i, (images, labels) in enumerate(train_loader):\n",
    "            model.train()\n",
    "\n",
    "            if torch.cuda.is_available():\n",
    "                images = images.cuda()\n",
    "                labels = labels.cuda()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            writer.add_scalar('trainning_loss', loss.item(), model.steps)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            step += 1\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "            if step % steps_before_print == 0:\n",
    "                # Calculate Accuracy\n",
    "                model.eval()\n",
    "                validation_loss, accuracy = utils.calculate_loss_and_accuracy(validation_loader, model, criterion, stop_at = 1200)\n",
    "                writer.add_scalar('validation_loss', validation_loss, model.steps)\n",
    "                writer.add_scalar('accuracy', accuracy, model.steps)\n",
    "                epoch_acc += accuracy\n",
    "                times_calculated += 1\n",
    "                # Print Loss\n",
    "                print('Iteration: {}/{} - ({:.2f}%). Loss: {}. Accuracy: {}'.format(step, total_size, step*100/total_size , loss.item(), accuracy))\n",
    "                if validation_loss < model.best_valdiation_loss:\n",
    "                    model.best_valdiation_loss = validation_loss\n",
    "                    print('Saving best model')\n",
    "                    save_model(model)\n",
    "                del validation_loss\n",
    "            del loss, outputs, images, labels\n",
    "\n",
    "        model.epochs += 1\n",
    "\n",
    "        #print('Epoch({}) avg loss: {} avg acc: {}'.format(epoch, epoch_loss/step, epoch_acc/times_calculated))\n",
    "        print('Epoch ', epoch)\n",
    "        #save_model(model, use_ts=True)                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Learning rate starting at 10e-03.\n",
    "\n",
    "learning_rate = 0.001\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train(50)\n",
    "save_model(model, use_ts=True)\n",
    "learning_rate = learning_rate / 10\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n",
    "train(50)\n",
    "save_model(model, use_ts=True)\n",
    "learning_rate = learning_rate / 10\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n",
    "train(50)\n",
    "save_model(model, use_ts=True)\n",
    "learning_rate = learning_rate / 10\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n",
    "train(20)\n",
    "save_model(model, use_ts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Saves model with a timestamp (prevents overwritting)\n",
    "save_model(model, use_ts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Check accuracy for all saved checkpoints\n",
    "\n",
    "for file in os.listdir(curr_folder):\n",
    "    if file.endswith(\".ckp\"):\n",
    "        print(file)\n",
    "        print('Model LOADED: ', curr_folder + '/' + file)\n",
    "        loaded_dict = torch.load(curr_folder + '/' + file)\n",
    "        #loaded_dict = {k: v for k, v in loaded_dict.items() if not k.startswith('combiner') }\n",
    "        #model.load_state_dict(loaded_dict, strict=False)\n",
    "        model.load_state_dict(loaded_dict)\n",
    "        model.eval()\n",
    "        validation_loss, accuracy = utils.calculate_loss_and_accuracy(validation_loader, model, criterion, 1500)\n",
    "        validation_loss, train_accuracy = utils.calculate_loss_and_accuracy(train_loader, model, criterion, 1500)\n",
    "        print('Validation Acc: {} \\t Train Acc: {}'.format(accuracy, train_accuracy))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
